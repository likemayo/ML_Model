{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe03ba9",
   "metadata": {},
   "source": [
    "**This Following code is implementation of Linear regression. Boston house prices dataset from Scikit Learn is used here and the goal is to estimate the price of a house in Boston using 13 attributes**\n",
    "\n",
    "*A closed-form solution, a ridge regression model, a polynomial transformation\n",
    "of degree 2 on the features, Lasso Regression are implemented using k-fold cross-validation and gradient descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fc322-021c-487d-ba43-10c177626a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae078e0-b4c7-477f-a1e2-7612539eb511",
   "metadata": {},
   "source": [
    "Following part is importing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "628f8f7f-87d2-4598-94a2-680e64390223",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "     warnings.filterwarnings(\"ignore\")\n",
    "     X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34672d-91b5-4196-9fa1-b5dfa49d3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f98ff-d57a-4ba5-b2e6-39ea4978ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Matrix Shape:\", X.shape) \n",
    "print(\"Target Vector Shape:\", y.shape) \n",
    "print(\"First 1 rows of Features:\\n\", X[:1])\n",
    "print(\"First 1 target values:\\n\", y[:1])\n",
    "print(\"Mean of each feature:\\n\", np.mean(X, axis=0))\n",
    "print(\"Standard deviation of each feature:\\n\", np.std(X, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ee16f-2a5e-4f28-ad09-1e93bf83fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(y, bins=30, color='blue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(\"House Price ($1000s)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of House Prices\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5556da-a061-486f-825a-1f5cec975572",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X[:,5], y, color='red', alpha=0.5)\n",
    "plt.xlabel(\"Average Number of Rooms (RM)\")\n",
    "plt.ylabel(\"House Price ($1000s)\")\n",
    "plt.title(\"Number of Rooms vs. House Price\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2664ef84-2d21-45f8-b92d-f9cbbfc3359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_theta(X,y):\n",
    "    m = X.shape[0]\n",
    "    theta = np.dot(np.linalg.inv(np.dot(X.T,X)),np.dot(X.T,y))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "37cbb3e1-d394-4e5b-ae12-9ce7f4929a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict1(X,theta):\n",
    "    preds = np.dot(X,theta)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "46016d8f-15e5-4d45-82c5-9ae5dc848008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b77a8090-5ee8-4651-85d6-76d75e1934b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_term(X):\n",
    "    m = X.shape[0]\n",
    "    X = np.append(X,np.ones((m,1)),axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b7a41058-0356-4445-95c3-1e15e9bef076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(X,y,k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True,random_state=42)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        theta = find_theta(X_train,y_train)\n",
    "        \n",
    "        y_train_pred = predict1(X_train,theta)\n",
    "        y_test_pred = predict1(X_test,theta)            \n",
    "        train_scores.append(mean_squared_error(y_train_pred,y_train))\n",
    "        test_scores.append(mean_squared_error(y_test_pred,y_test))\n",
    "    return np.mean(train_scores),np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "63b39808-a14b-4be7-88cd-4cbfb74463b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = add_bias_term(X)\n",
    "avg_train_score,avg_test_score = k_fold(X_b,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d3b6e-4f96-4179-a592-0b6f1c81c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Training MSE: {avg_train_score:.4f}\")\n",
    "print(f\"Average Test MSE: {avg_test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b1ae14-d4a0-4e23-aad5-4b53515af226",
   "metadata": {},
   "source": [
    "The following seciton is for ridge regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "03cf3838-f8f4-4e59-ad8f-bb62c737f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X,y,lambda_):\n",
    "    m,n = X.shape\n",
    "    I = np.eye(n)\n",
    "    theta = np.linalg.inv(X.T @ X + lambda_ * I) @ X.T @ y\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "856198b9-ce46-485d-a69c-1e2d6205f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,theta):\n",
    "    preds = np.dot(X,theta)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "026ccc2f-aef2-452f-b5db-cf4d2d8aaea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7213caf3-6370-4ece-a21c-7075a8d4ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X, y, lambdas, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    lambda_mse = []\n",
    "\n",
    "    for lambda_ in lambdas:\n",
    "        train_mse_list = []\n",
    "        test_mse_list = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            theta = ridge_regression(X_train, y_train, lambda_)\n",
    "\n",
    "\n",
    "            y_train_pred = predict(X_train, theta)\n",
    "            y_test_pred = predict(X_test, theta)\n",
    "\n",
    "            train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "            test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "            train_mse_list.append(train_mse)\n",
    "            test_mse_list.append(test_mse)\n",
    "\n",
    "        avg_train_mse = np.mean(train_mse_list)\n",
    "        avg_test_mse = np.mean(test_mse_list)\n",
    "\n",
    "        lambda_mse.append((lambda_, avg_train_mse, avg_test_mse))\n",
    "\n",
    "    return lambda_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d1f4c-76d5-4c89-8321-ed8e29c3eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(1, 7, num=13)\n",
    "lambda_mse = k_fold_cross_validation(X_b, y, lambdas, k=5)\n",
    "best_lambda, best_train_mse, best_test_mse = min(lambda_mse, key=lambda x: x[2])\n",
    "print(f\"Best λ: {best_lambda:.4f}\")\n",
    "print(f\"Training MSE with best λ: {best_train_mse:.4f}\")\n",
    "print(f\"Test MSE with best λ: {best_test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064da68-a290-4c68-aa18-5fd67f2b0a7b",
   "metadata": {},
   "source": [
    "The following is for polynomial closed form question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "18c8818a-bf79-4bf8-b5e7-e601ca7ffba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_closed_form(X, y, lambda_=1e-6): \n",
    "    n_features = X.shape[1]\n",
    "    I = np.eye(n_features)\n",
    "    return np.linalg.inv(X.T @ X + lambda_ * I) @ X.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b7c22028-d261-45f1-8569-1f6020916cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_kfold(X,y,k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True,random_state=42)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]  \n",
    "\n",
    "        theta = poly_closed_form(X_train,y_train)\n",
    "        \n",
    "        y_train_pred = X_train @ theta\n",
    "        y_test_pred = X_test@ theta         \n",
    "        train_scores.append(mean_squared_error(y_train_pred,y_train))\n",
    "        test_scores.append(mean_squared_error(y_test_pred,y_test))\n",
    "    return np.mean(train_scores),np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "09414ccd-c957-4477-bbfe-8075469ab43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bias = X_b[:,[-1]]\n",
    "X_feature = X_b[:,:-1]\n",
    "poly = PolynomialFeatures(degree=2,include_bias=False)\n",
    "X_poly_features = poly.fit_transform(X_feature)\n",
    "X_poly = np.hstack((X_poly_features,X_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "911f38c1-4bc2-4db4-b2d7-b62687b46551",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_score_ply,avg_test_score_ply = poly_kfold(X_poly,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db20fdd-30ce-48a6-a71a-a6acae69baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Training MSE: {avg_train_score_ply:.4f}\")\n",
    "print(f\"Average Test MSE: {avg_test_score_ply:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f094366c-a814-4f54-91b7-7259808a680f",
   "metadata": {},
   "source": [
    "Following part is for gradient descend for Multivariate Linear Regression question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e27e4456-ec7f-4911-bba6-d3e97509463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descend(X,y,learning_rate=0.01,epoch=1000):\n",
    "    m,n = X.shape\n",
    "    theta = np.random.randn(n,1) * 0.01\n",
    "    for _ in range(epoch):\n",
    "        y_pred = X.dot(theta)\n",
    "        gradient_d = -2/m * X.T.dot(y - y_pred)  \n",
    "        theta = theta - learning_rate*gradient_d\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "96849fef-e94c-400d-8a67-10805e2fe063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_kfold_desc(X,y,k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True,random_state=42)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]  \n",
    "        theta2 = gradient_descend(X_train,y_train)\n",
    "        y_train_pred = X_train @ theta2\n",
    "        y_test_pred = X_test @ theta2\n",
    "        train_scores.append(mean_squared_error(y_train_pred,y_train))\n",
    "        test_scores.append(mean_squared_error(y_test_pred,y_test)) \n",
    "    return np.mean(train_scores),np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f14c24a0-4ebd-4168-a7eb-1cf4c4b63ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_desc = (X_feature - np.mean(X_feature, axis=0)) / (np.std(X_feature, axis=0) + 1e-8)\n",
    "X_poly_desc = np.hstack((X_feature_desc,X_bias))\n",
    "y = y.reshape(-1,1)\n",
    "avg_train_score_plydesc,avg_test_score_plydesc = poly_kfold_desc(X_poly_desc,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4828a-ac72-48b8-b8c8-1d4c06afb178",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Training MSE: {avg_train_score_plydesc:.4f}\")\n",
    "print(f\"Average Test MSE: {avg_test_score_plydesc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3002fa-239e-48c9-8e47-460ad81ecd40",
   "metadata": {},
   "source": [
    "Following is Lasso Regression for gradient descend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "22a8abe9-923c-4592-8f22-c80988ee7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_model(X,y,learning_rate=0.01,l1_rate=0.1,epoch=1000):\n",
    "    m,n = X.shape\n",
    "    theta = np.random.randn(n,1) * 0.01\n",
    "    for _ in range(epoch):\n",
    "        y_pred = X.dot(theta)\n",
    "        gradient_d = (-2/m) * X.T @ (y - y_pred)\n",
    "        gradient_d += l1_rate * np.sign(theta)  \n",
    "        theta = theta - learning_rate * gradient_d\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bd074b28-65e1-4099-937c-532b72fc398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_kfold(X,y,k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True,random_state=42)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]  \n",
    "\n",
    "        theta = lasso_model(X_train,y_train)\n",
    "        \n",
    "        y_train_pred = X_train @ theta \n",
    "        y_test_pred = X_test@ theta       \n",
    "        train_scores.append(mean_squared_error(y_train_pred,y_train))\n",
    "        test_scores.append(mean_squared_error(y_test_pred,y_test))\n",
    "    return np.mean(train_scores),np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6996d-d6c5-4afe-ad72-214ee4c96ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = (X - np.mean(X, axis=0)) / (np.std(X, axis=0) + 1e-8)  \n",
    "X_scale = np.hstack((X_scale,X_bias))\n",
    "avg_lasso_test,avg_lasso_train = lasso_kfold(X_scale,y)\n",
    "print(f\"Average Training MSE: {avg_lasso_test:.4f}\")\n",
    "print(f\"Average Test MSE: {avg_lasso_train:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0a2ec-d779-4b9f-b095-b850f023d931",
   "metadata": {},
   "source": [
    "following is for elastic net implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b5a1902b-1980-45a7-bb40-0f67c3dc2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_model(X, y, epoch=1000, learning_rate=0.01, alpha=0.1, r=0.7):\n",
    "    m, n = X.shape\n",
    "    W = np.random.randn(n,1) * 0.01 \n",
    "    for _ in range(epoch):\n",
    "        y_pred = X.dot(W)\n",
    "        gradient_d = (-2/m) * X.T @ (y - y_pred)\n",
    "        l1_term = r*alpha*np.sign(W)\n",
    "        l2_term = (1 - r) * alpha * W  \n",
    "        gradient_d += l1_term + l2_term\n",
    "        W = W - learning_rate * gradient_d\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "22b4b8f4-7ca4-4e68-ba85-9923d08481de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_kfold(X, y, k=5, learning_rate=0.01, alpha=0.1, r=0.7):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        theta = elastic_net_model(X_train,y_train)\n",
    "        \n",
    "        y_train_pred = X_train @ theta\n",
    "        y_test_pred = X_test @ theta\n",
    "        \n",
    "        train_scores.append(mean_squared_error(y_train_pred, y_train))\n",
    "        test_scores.append(mean_squared_error(y_test_pred, y_test))\n",
    "    return np.mean(train_scores), np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc16ca5-7c91-4842-9e14-a56db8c62f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = (X - np.mean(X, axis=0)) / (np.std(X, axis=0) + 1e-8)\n",
    "X_scaled = np.hstack((X_scaled,X_bias))\n",
    "avg_train_mseelas, avg_test_mseelas = elastic_net_kfold(X_scaled, y)\n",
    "print(f\"Average Training MSE: {avg_train_mseelas:.4f}\")\n",
    "print(f\"Average Test MSE: {avg_test_mseelas:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24579e7-c5d2-4a4f-ac79-48a06fcf26a1",
   "metadata": {},
   "source": [
    "Question 10: I would choose gradient descend for linear regression with learning_rate = 0.01 and epoch = 1000 because it has the smallest average test MSE "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
