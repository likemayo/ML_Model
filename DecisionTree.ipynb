{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98e050c",
   "metadata": {},
   "source": [
    "1. **Dataset Introduction**: Iris and SpamBase datasets are used here. Iris has three classes and the task is to accurately predict one of the three subtypes of the Iris flower given four different physical features. Spambase is a binary classification task and the objective is to classify email messages as being spam or not. There are about 4600 instances\n",
    "\n",
    "2. **Implementation idea**: to determine best split, searched over all possible thresholds for a given feature and information gran detemrined by entropy is used to determine the best split with the most information gain.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc210bb-e58b-44f2-8bab-e750c418bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55eafae7-0085-420f-929d-72cb07fc2f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"iris.csv\", names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
    "with pd.option_context('future.no_silent_downcasting', True):\n",
    "    iris_df= iris_df.replace({'Iris-setosa':0, 'Iris-versicolor': 1, 'Iris-virginica': 2}).infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b8df47d-2407-4279-89d8-fd20dd4e1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self,nmin):\n",
    "        self.tree = None\n",
    "        self.nmin = nmin\n",
    "\n",
    "    def entropy(self,y):\n",
    "        probabilities = np.bincount(y) / len(y)\n",
    "        return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "    def information_gain(self,X,y,feature,threshold):\n",
    "        parent_entropy = self.entropy(y)\n",
    "        left_indices = X[:, feature] <= threshold\n",
    "        right_indices = X[:, feature] > threshold\n",
    "        if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
    "            return 0\n",
    "        n = len(y)\n",
    "        n_left, n_right = np.sum(left_indices), np.sum(right_indices)\n",
    "        e_left, e_right = self.entropy(y[left_indices]), self.entropy(y[right_indices])\n",
    "        child_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "    def most_common_label(self,y):\n",
    "        unique_labels, counts = np.unique(y, return_counts=True)\n",
    "        return unique_labels[np.argmax(counts)]\n",
    "\n",
    "    def best_split(self,X,y):\n",
    "        # find best feature and threshold\n",
    "        m,n = X.shape\n",
    "        best_gain = -1\n",
    "        best_feature,best_threshold = None,None\n",
    "        for feature in range(n):\n",
    "            thresholds = np.unique(X[:,feature])\n",
    "            for threshold in thresholds: \n",
    "                gain = self.information_gain(X,y,feature,threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return best_feature,best_threshold\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.tree = self.grow_tree(X,y)\n",
    "\n",
    "    def grow_tree(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_labels = len(np.unique(y))\n",
    "        \n",
    "        if num_samples < self.nmin or num_labels ==1:\n",
    "            leaf_value = self.most_common_label(y)\n",
    "            return leaf_value \n",
    "            \n",
    "        best_feature, best_threshold = self.best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return self.most_common_label(y)\n",
    "            \n",
    "        left_indices = X[:,best_feature] <= best_threshold\n",
    "        right_indices = X[:,best_feature] > best_threshold\n",
    "        \n",
    "        left_subtree = self.grow_tree(X[left_indices], y[left_indices])\n",
    "        right_subtree = self.grow_tree(X[right_indices], y[right_indices])\n",
    "        \n",
    "        return (best_feature, best_threshold, left_subtree, right_subtree)\n",
    "\n",
    "    def predict_sample(self,sample,tree):\n",
    "        if not isinstance(tree, tuple):  \n",
    "            return tree\n",
    "        feature, threshold, left_subtree, right_subtree = tree\n",
    "        if sample[feature] <= threshold:\n",
    "            return self.predict_sample(sample, left_subtree)\n",
    "        else:\n",
    "            return self.predict_sample(sample, right_subtree)\n",
    "\n",
    "    def predict(self,X):\n",
    "        return [self.predict_sample(x, self.tree) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cec1ddbc-c372-403c-a67a-b9546d9949cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, nmin_values):\n",
    "    results = {}\n",
    "    for nmin in nmin_values:\n",
    "        accuracies = []\n",
    "        print(f\"Evaluating nmin={nmin}...\") \n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            tree = DecisionTree(nmin=nmin)\n",
    "            tree.fit(X_train, y_train)            \n",
    "            y_pred = tree.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        results[nmin] = (np.mean(accuracies), np.std(accuracies))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf9b6a52-08f5-4209-bb93-447220ced57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Iris dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Iris dataset...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cb01142-6b88-4690-a948-ad6516628173",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris = iris_df.iloc[:, :-1].values  \n",
    "y_iris = iris_df.iloc[:, -1].values  \n",
    "nmin_iris = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe799225-d80e-42f4-b1be-f471c0421324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating nmin=5...\n",
      "Evaluating nmin=10...\n",
      "Evaluating nmin=15...\n",
      "Evaluating nmin=20...\n",
      "nmin=5: Accuracy = 0.9333 ± 0.0516\n",
      "nmin=10: Accuracy = 0.9467 ± 0.0499\n",
      "nmin=15: Accuracy = 0.9467 ± 0.0499\n",
      "nmin=20: Accuracy = 0.9467 ± 0.0499\n"
     ]
    }
   ],
   "source": [
    "iris_results = evaluate_model(X_iris, y_iris, nmin_iris)\n",
    "for nmin, (mean_acc, std_acc) in iris_results.items():\n",
    "    print(f\"nmin={nmin}: Accuracy = {mean_acc:.4f} ± {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6850c0d0-71c9-4c50-b427-d7aa4f62ef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...   0.41  \\\n",
      "0     0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
      "1     0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
      "2     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
      "3     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
      "4     0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.000   \n",
      "...    ...   ...     ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
      "4595  0.31  0.00    0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
      "4596  0.00  0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
      "4597  0.30  0.00    0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
      "4598  0.96  0.00    0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
      "4599  0.00  0.00    0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
      "\n",
      "       0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
      "0     0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
      "1     0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
      "2     0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
      "3     0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
      "4     0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
      "...     ...   ...    ...    ...    ...    ...  ...   ... ..  \n",
      "4595  0.232   0.0  0.000  0.000  0.000  1.142    3    88  0  \n",
      "4596  0.000   0.0  0.353  0.000  0.000  1.555    4    14  0  \n",
      "4597  0.718   0.0  0.000  0.000  0.000  1.404    6   118  0  \n",
      "4598  0.057   0.0  0.000  0.000  0.000  1.147    5    78  0  \n",
      "4599  0.000   0.0  0.125  0.000  0.000  1.250    5    40  0  \n",
      "\n",
      "[4600 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "spam_df = pd.read_csv('spambase.csv') \n",
    "nmin_spam= [5, 10, 15, 20,25]\n",
    "X_spam = spam_df.iloc[:, :-1].values  \n",
    "y_spam = spam_df.iloc[:, -1].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83f05840-0047-4d25-920e-d6bce8a3ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating nmin=5...\n",
      "Evaluating nmin=10...\n",
      "Evaluating nmin=15...\n",
      "Evaluating nmin=20...\n",
      "Evaluating nmin=25...\n",
      "{5: (0.9189130434782609, 0.01573798938933761), 10: (0.9173913043478261, 0.01552484440987574), 15: (0.9197826086956521, 0.01625209016657884), 20: (0.9202173913043479, 0.016671234408728565), 25: (0.9204347826086956, 0.015921594281391796)}\n",
      "nmin=5: Accuracy = 0.9189 ± 0.0157\n",
      "nmin=10: Accuracy = 0.9174 ± 0.0155\n",
      "nmin=15: Accuracy = 0.9198 ± 0.0163\n",
      "nmin=20: Accuracy = 0.9202 ± 0.0167\n",
      "nmin=25: Accuracy = 0.9204 ± 0.0159\n"
     ]
    }
   ],
   "source": [
    "spam_result = evaluate_model(X_spam,y_spam,nmin_spam)\n",
    "print(spam_result)\n",
    "for nmin,(mean_acc,std_acc) in spam_result.items():\n",
    "    print(f\"nmin={nmin}: Accuracy = {mean_acc:.4f} ± {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade65908-dd92-4ed0-bcb7-7d7e34248230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
